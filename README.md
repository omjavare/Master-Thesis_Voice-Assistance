# ğŸ™ï¸ Whisper Realtime Echo ğŸš€

A modern GUI for Faster Whisper speech recognition model using Flet framework.

> âš ï¸ This application has been tested and confirmed working on Windows. While it may work on other platforms (Linux, macOS), they have not been officially tested.

![Demo](demo.png)

## âœ¨ Features

- ğŸ”Š Transcribe audio files with a beautiful UI
- ğŸ¤ Record audio directly and transcribe it
- ğŸ§ Live transcription with real-time speech recognition
- ğŸŒ Choose between English-only and multilingual models
- ğŸ—£ï¸ Select language for multilingual models (auto-detect available)
- ğŸŒ Translate any language to English text
- ğŸ“ Select model size with VRAM/speed indicators
- ğŸ’» GPU (CUDA) or CPU processing
- ğŸ“Š Real-time transcription status
- ğŸ§© Modular, maintainable codebase
- ğŸ“‹ Copy results to clipboard with history access
- ğŸŒ“ Toggle between light and dark themes

## ğŸ“‹ Model Information

| Size | Parameters | English-only | Multilingual | VRAM | Speed |
|------|------------|--------------|--------------|------|-------|
| tiny | 39 M | âœ… tiny.en | âœ… tiny | ~1 GB | ~10x |
| base | 74 M | âœ… base.en | âœ… base | ~1 GB | ~7x |
| small | 244 M | âœ… small.en | âœ… small | ~2 GB | ~4x |
| medium | 769 M | âœ… medium.en | âœ… medium | ~5 GB | ~2x |
| large | 1550 M | âŒ N/A | âœ… large | ~10 GB | 1x |
| turbo | 809 M | âŒ N/A | âœ… turbo | ~6 GB | ~8x |

> ğŸ’¡ English-only models typically perform better for English transcription.

## ğŸš€ Included Pre-quantized Models

For optimal real-time transcription speed, the application includes pre-quantized int8 versions of the tiny models:

- `int8_tiny_en`: Pre-quantized tiny.en model for English transcription
- `int8_tiny`: Pre-quantized tiny model for multilingual transcription

These models were created using CTranslate2's conversion tool with the following command:

```bash
ct2-transformers-converter --model openai/whisper-tiny.en --output_dir int8_tiny_en --copy_files tokenizer.json preprocessor_config.json --quantization int8
```

## ğŸš€ Quick Start

### Installation

```bash
# Clone repository
git clone https://gitlab.com/alouiadel/whisper-realtime-echo.git
cd whisper-realtime-echo

# Create and activate virtual environment
# For Windows:
python -m venv venv
venv\Scripts\activate

# For macOS/Linux:
python -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

> ğŸ”¥ **For GPU acceleration:** If you want to use CUDA for GPU acceleration, install the appropriate PyTorch version from [PyTorch official installation guide](https://pytorch.org/get-started/locally/)

### Usage

```bash
# Run the application
python main.py
```

1. ğŸ“‚ Click "Select Audio File" or ğŸ¤ "Start Recording"
2. ğŸŒ Choose model type and size
3. ğŸ“Š Select processing device (CPU/GPU)
4. â–¶ï¸ Click "Transcribe" for file processing or ğŸ™ï¸ "Start Live" for real-time transcription
5. ğŸ“ View results and use the toolbar to:
   - ğŸ“‹ Copy to clipboard
   - ğŸ“œ Access transcript history
   - ğŸŒ“ Toggle theme (top-right corner)

## ğŸ™ï¸ Live Transcription:
  - Provides real-time speech-to-text from your microphone
  - Automatically detects and processes speech in chunks
  - Optimized for maximum responsiveness:
    - Uses int8 quantization (reduces memory usage by ~40%)
    - Reduced beam size (1 instead of 5)
    - Greedy decoding with temperature=0
    - Independent chunk processing
    - Disabled timestamps generation
  - Best practices:
    - Works best in quiet environments
    - Smaller models offer faster response times
    - Use a clear, consistent speaking voice

## ğŸ§ Supported Audio Formats

Whisper leverages ffmpeg to process audio, supporting a wide range of formats:
- Audio files: wav, mp3, m4a, ogg, flac, opus, amr
- Video files: mp4 (and other video formats with audio tracks)

## ğŸ“œ Clipboard History

- View, copy, and reuse previous transcriptions
- Saved between sessions with timestamps and model info
- Most recent 50 entries are retained

## ğŸ“ Notes & Limitations

- **Language Selection**: Helps Whisper optimize recognition but doesn't translate content. English audio will still be transcribed as English even when another language is selected.

- **Transcribe vs. Translate Modes**:
  - **Transcribe**: Converts speech to text in the original language (default)
  - **Translate**: Converts speech from any language to English text

- **Translation Best Practices**:
  - Automatically sets language to "Auto-detect" for optimal results
  - Works best with larger models (large or turbo) and clear audio
  - Some languages may require transcribing first, then using a separate translation service

- **System Requirements**: If crashes occur, try using a smaller model or ensure your system meets the memory requirements in the model table.

## ğŸ™ Credits

This project is powered by [Faster Whisper](https://github.com/SYSTRAN/faster-whisper), a highly optimized implementation of OpenAI's Whisper. The Whisper model was trained on a large dataset of diverse audio and is capable of multilingual speech recognition, translation, and language identification.

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
